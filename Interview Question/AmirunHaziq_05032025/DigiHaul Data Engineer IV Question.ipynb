{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ef6d93",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "## Python & Data Manipulation Test: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b73e2d",
   "metadata": {},
   "source": [
    "### 1.1 Data Extraction Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "558938e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. The data has been saved to stock_data.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Extraction Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-03-05 14:30:00+00:00</th>\n",
       "      <td>235.867996</td>\n",
       "      <td>235.949997</td>\n",
       "      <td>234.583496</td>\n",
       "      <td>235.494995</td>\n",
       "      <td>1623165</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 14:31:00+00:00</th>\n",
       "      <td>234.840103</td>\n",
       "      <td>235.851898</td>\n",
       "      <td>234.840103</td>\n",
       "      <td>235.851898</td>\n",
       "      <td>177990</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 14:32:00+00:00</th>\n",
       "      <td>235.160004</td>\n",
       "      <td>235.440002</td>\n",
       "      <td>234.800003</td>\n",
       "      <td>234.839996</td>\n",
       "      <td>155925</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 14:33:00+00:00</th>\n",
       "      <td>235.639999</td>\n",
       "      <td>235.907303</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.160004</td>\n",
       "      <td>188584</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 14:34:00+00:00</th>\n",
       "      <td>235.119995</td>\n",
       "      <td>235.729996</td>\n",
       "      <td>235.065002</td>\n",
       "      <td>235.649994</td>\n",
       "      <td>110201</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 15:41:00+00:00</th>\n",
       "      <td>170.355194</td>\n",
       "      <td>170.355194</td>\n",
       "      <td>170.240005</td>\n",
       "      <td>170.279999</td>\n",
       "      <td>38159</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 15:42:00+00:00</th>\n",
       "      <td>169.975006</td>\n",
       "      <td>170.360001</td>\n",
       "      <td>169.949997</td>\n",
       "      <td>170.350006</td>\n",
       "      <td>56346</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 15:43:00+00:00</th>\n",
       "      <td>170.212006</td>\n",
       "      <td>170.335007</td>\n",
       "      <td>169.949997</td>\n",
       "      <td>169.949997</td>\n",
       "      <td>40670</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 15:44:00+00:00</th>\n",
       "      <td>170.229996</td>\n",
       "      <td>170.259995</td>\n",
       "      <td>170.160004</td>\n",
       "      <td>170.205002</td>\n",
       "      <td>20859</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 15:45:00+00:00</th>\n",
       "      <td>170.263199</td>\n",
       "      <td>170.263199</td>\n",
       "      <td>170.263199</td>\n",
       "      <td>170.263199</td>\n",
       "      <td>0</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2025-03-05 23:45:21.909046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Close        High         Low        Open  \\\n",
       "Datetime                                                                    \n",
       "2025-03-05 14:30:00+00:00  235.867996  235.949997  234.583496  235.494995   \n",
       "2025-03-05 14:31:00+00:00  234.840103  235.851898  234.840103  235.851898   \n",
       "2025-03-05 14:32:00+00:00  235.160004  235.440002  234.800003  234.839996   \n",
       "2025-03-05 14:33:00+00:00  235.639999  235.907303  235.000000  235.160004   \n",
       "2025-03-05 14:34:00+00:00  235.119995  235.729996  235.065002  235.649994   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-03-05 15:41:00+00:00  170.355194  170.355194  170.240005  170.279999   \n",
       "2025-03-05 15:42:00+00:00  169.975006  170.360001  169.949997  170.350006   \n",
       "2025-03-05 15:43:00+00:00  170.212006  170.335007  169.949997  169.949997   \n",
       "2025-03-05 15:44:00+00:00  170.229996  170.259995  170.160004  170.205002   \n",
       "2025-03-05 15:45:00+00:00  170.263199  170.263199  170.263199  170.263199   \n",
       "\n",
       "                            Volume Symbol            Extraction Time  \n",
       "Datetime                                                              \n",
       "2025-03-05 14:30:00+00:00  1623165  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 14:31:00+00:00   177990  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 14:32:00+00:00   155925  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 14:33:00+00:00   188584  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 14:34:00+00:00   110201  GOOGL 2025-03-05 23:45:21.909046  \n",
       "...                            ...    ...                        ...  \n",
       "2025-03-05 15:41:00+00:00    38159  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 15:42:00+00:00    56346  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 15:43:00+00:00    40670  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 15:44:00+00:00    20859  GOOGL 2025-03-05 23:45:21.909046  \n",
       "2025-03-05 15:45:00+00:00        0  GOOGL 2025-03-05 23:45:21.909046  \n",
       "\n",
       "[228 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of stock symbols\n",
    "symbols = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Initialize an empty DataFrame to store the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each symbol and retrieve the data\n",
    "for symbol in symbols:\n",
    "    # Retrieve data for the symbol\n",
    "    stock_data = yf.download(symbol, period=\"1d\", interval=\"1m\", multi_level_index = False)\n",
    "    \n",
    "    # Append the data to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, stock_data])\n",
    "    \n",
    "    # Add a column for the symbol\n",
    "    all_data['Symbol'] = symbol\n",
    "\n",
    "# Add a timestamp indicating the extraction time\n",
    "all_data['Extraction Time'] = datetime.now()\n",
    "\n",
    "# Reorder columns to match the desired output format\n",
    "all_data = all_data[['Close', 'High', 'Low', 'Open', 'Volume', 'Symbol', 'Extraction Time']]\n",
    "\n",
    "# Save the resulting data in CSV format\n",
    "all_data.to_csv(\"./data/csv/stock_data.csv\", index=False)\n",
    "\n",
    "print(\"Data extraction complete. The data has been saved to stock_data.csv.\")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8adffe",
   "metadata": {},
   "source": [
    "![Image](./assets/img/Python_Extract_Result.png \"Python Extract Result\")\n",
    "#### See result in ./data/csv/stock_data.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6874622",
   "metadata": {},
   "source": [
    "### 1.2 Data Storage\n",
    "#### Unable to register my card. Choose not to do 1.2 for additional point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b184b7",
   "metadata": {},
   "source": [
    "# -----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab77bd5",
   "metadata": {},
   "source": [
    "# Snowflake Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83946182",
   "metadata": {},
   "source": [
    "### 2. Create a flow chart detailing your project end to end from source till data visualization layer? \n",
    "![Image](./assets/img/End_to_End_Flowchart.png \"End to End Flowchart\")\n",
    "\n",
    "#### Can refer to ./assets/img/End_to_End_Flowchart.png or ./assets/img/End_to_End_Flowchart.drawio also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6b6f3",
   "metadata": {},
   "source": [
    "### 3. What are the ways you can load data into snowflake? When to use which?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cca69",
   "metadata": {},
   "source": [
    "### 1. Using the Web Interface\n",
    "\n",
    "#### Description: Load data directly through Snowflake's web interface.\n",
    "\n",
    "#### When to Use: Ideal for small datasets or ad-hoc data loading tasks.\n",
    "\n",
    "#### Example: Uploading a CSV file manually for quick analysis.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Using SQL Commands (COPY INTO)\n",
    "\n",
    "#### Description: Use SQL commands to load data from staged files into Snowflake tables.\n",
    "\n",
    "#### When to Use: Suitable for bulk loading of large datasets.\n",
    "\n",
    "#### Example: Loading data from Amazon S3 or Azure Blob Storage using the COPY INTO command.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Using Snowpipe\n",
    "\n",
    "#### Description: Snowpipe is a continuous data ingestion service that loads data as soon as it is available in a stage.\n",
    "\n",
    "#### When to Use: Best for near real-time data loading and continuous data streams.\n",
    "\n",
    "#### Example: Loading log files or streaming data from IoT devices.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Using Snowpipe Streaming\n",
    "\n",
    "#### Description: Snowpipe Streaming allows for continuous ingestion of data streams.\n",
    "\n",
    "#### When to Use: Ideal for scenarios requiring low-latency data ingestion.\n",
    "\n",
    "#### Example: Real-time analytics on streaming data from Kafka or other streaming platforms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 5. Using External Tables\n",
    "\n",
    "#### Description: Query data directly from external storage without loading it into Snowflake.\n",
    "\n",
    "#### When to Use: Useful for accessing large datasets stored externally without the need for immediate loading.\n",
    "\n",
    "#### Example: Querying data stored in Amazon S3 or Google Cloud Storage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 6. Using Third-Party ETL Tools\n",
    "\n",
    "#### Description: Use ETL tools like Talend, Informatica, or Hevo Data to load data into Snowflake.\n",
    "\n",
    "#### When to Use: Suitable for complex data transformations and integrations from multiple sources.\n",
    "\n",
    "#### Example: Integrating data from various databases and applications into Snowflake.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 7. Using SnowSQL\n",
    "\n",
    "#### Description: SnowSQL is a command-line tool for interacting with Snowflake, including data loading.\n",
    "\n",
    "#### When to Use: Ideal for scripting and automation of data loading tasks.\n",
    "\n",
    "#### Example: Automating nightly data loads from local files or cloud storage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 8. Using API Integration\n",
    "\n",
    "#### Description: Use Snowflake's REST API to load data programmatically.\n",
    "\n",
    "#### When to Use: Best for custom applications and integrations requiring programmatic data loading.\n",
    "\n",
    "#### Example: Loading data from a custom application or microservice.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 9. Using Data Sharing\n",
    "\n",
    "#### Description: Share data between Snowflake accounts without physically moving the data.\n",
    "\n",
    "#### When to Use: Useful for collaboration and sharing data with partners or other departments.\n",
    "\n",
    "#### Example: Sharing a dataset with a partner organization for joint analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 10. Using Data Replication\n",
    "\n",
    "#### Description: Replicate data from one Snowflake account to another.\n",
    "\n",
    "#### When to Use: Ideal for disaster recovery and data synchronization between environments.\n",
    "\n",
    "#### Example: Replicating data from a production account to a backup account.\n",
    "\n",
    "\n",
    "##### SOURCE: https://docs.snowflake.com/en/user-guide/data-load-overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b3925",
   "metadata": {},
   "source": [
    "### 4. You have a JSON data column in a table storing Digihaul customer feedback with the following keys: “customer_id”, “feedback_text”, and “timestamp”. Write a query to extract and display the feedback text and timestamp for a specific customer_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56267d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assuming the table name is customer\n",
    "## Assuming the column name is cust_data\n",
    "\n",
    "SELECT \n",
    "    cust_data:feedback_text::string AS feedback_text, \n",
    "    cust_data:timestamp::string AS timestamp \n",
    "FROM \n",
    "    customer \n",
    "WHERE \n",
    "    cust_data:customer_id::string = '12345';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b884eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./assets/img/Snowflake_JSON_Result.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display an image from a local file\n",
    "Image(url=\"./assets/img/Snowflake_JSON_Result.png\", width=700, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e29acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
