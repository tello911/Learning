{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ef6d93",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "## Python & Data Manipulation Test: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b73e2d",
   "metadata": {},
   "source": [
    "### 1.1 Data Extraction Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e499930",
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting Data by Ticker and Storing in Blob [4 Points]\n",
    "Given that all ticker data is stored in a table, how would you split the data based on the ticker and store each subset in a blob storage?\n",
    "Modify the file name format to include the ticker name, datetime, and ingestion timestamp.\n",
    "Expected file format: tickername_datetime_ingested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558938e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='fc.yahoo.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1006)')))\"))\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MSFT']: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='fc.yahoo.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1006)')))\"))\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GOOGL']: SSLError(MaxRetryError(\"HTTPSConnectionPool(host='fc.yahoo.com', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate (_ssl.c:1006)')))\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. The data has been saved to stock_data.csv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Extraction Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Close, High, Low, Open, Volume, Symbol, Extraction Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of stock symbols\n",
    "symbols = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Initialize an empty DataFrame to store the data\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each symbol and retrieve the data\n",
    "for symbol in symbols:\n",
    "    # Retrieve data for the symbol\n",
    "    stock_data = yf.download(symbol, period=\"1d\", interval=\"1m\", multi_level_index = False)\n",
    "    \n",
    "    # Append the data to the all_data DataFrame\n",
    "    all_data = pd.concat([all_data, stock_data])\n",
    "    \n",
    "    # Add a column for the symbol\n",
    "    all_data['Symbol'] = symbol\n",
    "\n",
    "# Add a timestamp indicating the extraction time\n",
    "all_data['Extraction Time'] = datetime.now()\n",
    "\n",
    "# Reorder columns to match the desired output format\n",
    "all_data = all_data[['Close', 'High', 'Low', 'Open', 'Volume', 'Symbol', 'Extraction Time']]\n",
    "\n",
    "print(\"Data extraction complete. The data has been saved to stock_data.csv.\")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8adffe",
   "metadata": {},
   "source": [
    "![Image](./assets/img/Python_Extract_Result.png \"Python Extract Result\")\n",
    "#### See result in ./data/csv/stock_data.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6874622",
   "metadata": {},
   "source": [
    "### 1.2 Data Storage\n",
    "#### Unable to register my card. Choose not to do 1.2 for additional point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b184b7",
   "metadata": {},
   "source": [
    "# -----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab77bd5",
   "metadata": {},
   "source": [
    "# Snowflake Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83946182",
   "metadata": {},
   "source": [
    "### 2. Create a flow chart detailing your project end to end from source till data visualization layer? \n",
    "![Image](./assets/img/End_to_End_Flowchart.png \"End to End Flowchart\")\n",
    "\n",
    "#### Can refer to ./assets/img/End_to_End_Flowchart.png or ./assets/img/End_to_End_Flowchart.drawio also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6b6f3",
   "metadata": {},
   "source": [
    "### 3. What are the ways you can load data into snowflake? When to use which?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94cca69",
   "metadata": {},
   "source": [
    "### 1. Using the Web Interface\n",
    "\n",
    "#### Description: Load data directly through Snowflake's web interface.\n",
    "\n",
    "#### When to Use: Ideal for small datasets or ad-hoc data loading tasks.\n",
    "\n",
    "#### Example: Uploading a CSV file manually for quick analysis.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Using SQL Commands (COPY INTO)\n",
    "\n",
    "#### Description: Use SQL commands to load data from staged files into Snowflake tables.\n",
    "\n",
    "#### When to Use: Suitable for bulk loading of large datasets.\n",
    "\n",
    "#### Example: Loading data from Amazon S3 or Azure Blob Storage using the COPY INTO command.\n",
    "\n",
    "\n",
    "\n",
    "### 3. Using Snowpipe\n",
    "\n",
    "#### Description: Snowpipe is a continuous data ingestion service that loads data as soon as it is available in a stage.\n",
    "\n",
    "#### When to Use: Best for near real-time data loading and continuous data streams.\n",
    "\n",
    "#### Example: Loading log files or streaming data from IoT devices.\n",
    "\n",
    "\n",
    "\n",
    "### 4. Using Snowpipe Streaming\n",
    "\n",
    "#### Description: Snowpipe Streaming allows for continuous ingestion of data streams.\n",
    "\n",
    "#### When to Use: Ideal for scenarios requiring low-latency data ingestion.\n",
    "\n",
    "#### Example: Real-time analytics on streaming data from Kafka or other streaming platforms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 5. Using External Tables\n",
    "\n",
    "#### Description: Query data directly from external storage without loading it into Snowflake.\n",
    "\n",
    "#### When to Use: Useful for accessing large datasets stored externally without the need for immediate loading.\n",
    "\n",
    "#### Example: Querying data stored in Amazon S3 or Google Cloud Storage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 6. Using Third-Party ETL Tools\n",
    "\n",
    "#### Description: Use ETL tools like Talend, Informatica, or Hevo Data to load data into Snowflake.\n",
    "\n",
    "#### When to Use: Suitable for complex data transformations and integrations from multiple sources.\n",
    "\n",
    "#### Example: Integrating data from various databases and applications into Snowflake.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 7. Using SnowSQL\n",
    "\n",
    "#### Description: SnowSQL is a command-line tool for interacting with Snowflake, including data loading.\n",
    "\n",
    "#### When to Use: Ideal for scripting and automation of data loading tasks.\n",
    "\n",
    "#### Example: Automating nightly data loads from local files or cloud storage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 8. Using API Integration\n",
    "\n",
    "#### Description: Use Snowflake's REST API to load data programmatically.\n",
    "\n",
    "#### When to Use: Best for custom applications and integrations requiring programmatic data loading.\n",
    "\n",
    "#### Example: Loading data from a custom application or microservice.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 9. Using Data Sharing\n",
    "\n",
    "#### Description: Share data between Snowflake accounts without physically moving the data.\n",
    "\n",
    "#### When to Use: Useful for collaboration and sharing data with partners or other departments.\n",
    "\n",
    "#### Example: Sharing a dataset with a partner organization for joint analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 10. Using Data Replication\n",
    "\n",
    "#### Description: Replicate data from one Snowflake account to another.\n",
    "\n",
    "#### When to Use: Ideal for disaster recovery and data synchronization between environments.\n",
    "\n",
    "#### Example: Replicating data from a production account to a backup account.\n",
    "\n",
    "\n",
    "##### SOURCE: https://docs.snowflake.com/en/user-guide/data-load-overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b3925",
   "metadata": {},
   "source": [
    "### 4. You have a JSON data column in a table storing Digihaul customer feedback with the following keys: “customer_id”, “feedback_text”, and “timestamp”. Write a query to extract and display the feedback text and timestamp for a specific customer_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56267d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assuming the table name is customer\n",
    "## Assuming the column name is cust_data\n",
    "\n",
    "SELECT \n",
    "    cust_data:feedback_text::string AS feedback_text, \n",
    "    cust_data:timestamp::string AS timestamp \n",
    "FROM \n",
    "    customer \n",
    "WHERE \n",
    "    cust_data:customer_id::string = '12345';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b884eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./assets/img/Snowflake_JSON_Result.png\" width=\"700\" height=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Display an image from a local file\n",
    "Image(url=\"./assets/img/Snowflake_JSON_Result.png\", width=700, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e29acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
